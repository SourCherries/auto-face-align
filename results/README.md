# Evaluation of DLIB and AFA
To test DLIB landmark detection and our GPA-based alignment procedure in the typical use-case for psychology researchers, we use 3 different databases of face photographs.

The databases we used: the CAS-PEAL database of Chinese faces (Gao et al., 2008); the Glasgow Unfamiliar Face Database GUFD (Burton et al., 2010); and faces from the Kent Face Matching Test KFMT (Fysh & Bindemann, 2018).

In particular, GUFD and KFMT are tailored to the study of face perception in realistic scenarios, so the faces from these databases were photographed with variable quality cameras and resolutions and allowed for natural poses instead of a strictly frontal-parallel orientation of the face.

Photographic subjects in both the GUFD and KFMT databases were allowed to have their hair worn in any fashion. And unlike the other two databases, photographic subjects in the KFMT database were allowed to wear glasses.

Image resolutions in width-by-height (pixels) are 360 x 480 and 350 x 518 for the CAS-PEAL and GUFD databases, respectively. KFMT was divided between KFMT-DC and KFMT-ID which were photos taken in-lab (283 x 332 pixels) and pre-existing photo-identification (142 x 192) obtained from the same people.

Given variability in the area occupied by faces across these databases (due to camera distance and focus), perhaps a better metric for image resolution that allows comparison across databases is the mean eye distance measured using AFA. Those eye distances (pixels) are listed in the table below.

## Replicate this analysis yourself
Contact the authors of these databases and request a copy of their faces. Put those faces into the appropriate folders in this directory. Then run the following AFA-driven Python scripts:


```
python results_1_preprocessing.py
```
This script will calculate landmarks for all faces in all databases.
It will then allow you to view each face with landmarks overlaid, one at a time.
Careful observation of each figure shows very few instances (13 out of 1959 total) where landmark placements are inaccurate.
A detailed breakdown of these **failed landmark placements** is in the table below.

The script also determines the number of **failed face detections**, which is very rare (1 out of 1959 total).

Among the many outputs is [table-DLIB-failures.csv](table-DLIB-failures.csv).

Finally, new aligned faces are generated and their landmarks are calculated.

```
python get_eye_distances_original.py
```
This simply measures the average distance between eyes (pixels) in each database. Output file is [table-eye-distances.csv](table-eye-distances.csv).

```
python results_2_main.py
```
For each database, visualize the distribution of each landmark across faces as an ellipsoid centered on the mean position of that landmark. Ellipsoid orientation is determined by a PCA on the values of X and Y coordinates across faces, and length and width are 2 times the standard deviations along the principal components. Ellipsoid size should be relatively small and somewhat uniform across landmarks if AFA does a good job of alignment.

For each database, these ellipsoids are then overlaid on the mean of aligned faces. If AFA does a good job of alignment, mean faces should have strong local contrast around facial features, relative to other parts of the face.

```
python make_figures.py
```
Simply put together the ellipsoid images written by previous script into a single figure.

```
python results_3_additional.py
```
Show landmarks overlaid on each aligned face for all faces in each database.
Visual inspection shows all landmark placement to be excellent in all of the aligned faces generated by AFA, and alignments to be good.



## DLIB performance

|Database	|Eye Distance, pixels	|Race	|n	|Failed Face Detections	|Failed Landmark Placement|
| :--- | :---: | :---: | :---: | :---: | :---: |
|CAS-female	|84	|Chinese	|437	|0	|0|
|CAS-male	|84	|Chinese|	589|	0|	0|
|GUFD-female	|112	|Predominantly Caucasian|	106|	0|	0|
|GUFD-male	|112	|Predominantly Caucasian|	323|	0|	0|
|KUFT-DC	|55	|Mostly Caucasian|	252|	0|	2|
|KUFT-ID	|43	|Mostly Caucasian|	252|	1|	10|
|Total|		|	|1959	|1	|12|

Using AFA, we use mean eye-distance in pixels measured on the original faces as a measure of resolution for each database.

The 2 cases of failed landmark placement for KUFT-DC are for subjects wearing glasses.

Among the 10 cases of failed landmark placement for KUFT-ID: 5 are for subjects wearing glasses, 1 is for a subject with an pose that is highly deviant from frontal-parallel, 1 is for a subject with hair covering an eyebrow. The other (3) cases are difficult to explain but they were all non-Caucasian (Black specifically) and we suspect that this deserves greater attention.

## AFA performance (neutral expression)
<!-- ![](landmark-dist-all.png) -->

<img src="landmark-dist-all.png" height="500">

Distributions of landmarks (red ellipses) overlaid on mean of GPA-aligned images. Ellipse orientation based on angle between first and second eigenvectors of PCA applied to landmarks across all faces in a single category. Ellipse length and width are 2 SD of variability along those eigenvectors. Analysis is done separately for 4 categories of faces: Chinese females from the CAS database (a); Chinese males from the CAS database (b); predominantly Caucasian female faces from the GUFD database (c); predominantly Caucasian male faces from the GUFD database (d); in-lab photos of mostly Caucasian faces (mixed gender) from the KUFD database; and low-resolution photo-ID of mostly Caucasian faces (mixed gender and expression) from the KUFD database. Despite SD being a non-robust measure of variability that is strongly inflated by outliers, each ellipse is quite small relative to the size of facial features. Ellipse sizes are also roughly uniform across the different landmarks. The means of aligned faces have high contrast and normal-looking facial features. That provides additional, qualitative validation of the entire GPA-alignment process performed by AFA (including landmark detection).

## AFA performance (emotionally expressive)
<img src="landmark-dist-nim-all.png" height="150">

<!-- expression = ["an", "ca", "di", "fe", "ha", "ne", "sa", "sp"] -->

Distributions of landmarks (red ellipses) overlaid on mean of GPA-aligned images of emotionally expressive faces. Unlike in the previous figure, alignments for these faces were based only on eye landmarks.
[a to h] corresponds to anger, CA, disgust, fear, happy, neutral, sad, and surprised for closed mouth expressions. There was only 1 face available for closed-mouth surprise so that category has been excluded. [i to p] corresponds to anger, CA, disgust, fear, happy, neutral, sad, and surprised for open mouth expressions.

***TO DO***
What is CA?
Reference for NIMSTIM?
Comments on results for NIM?

## References
>Gao, W., Cao, B., Shan, S., Chen, X., Zhou, D., Zhang, X., & Zhao, D. (2008). The CAS-PEAL large-scale Chinese face database and baseline evaluations. IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans, 38(1), 149–161.

>Burton, A. M., White, D., & McNeill, A. (2010). The Glasgow Face Matching Test. Behavior Research Methods, 42(1), 286–291. https://doi.org/10.3758/BRM.42.1.286

>Fysh, M. C., & Bindemann, M. (2018). The Kent Face Matching Test. British Journal of Psychology, 109(2), 219–231. https://doi.org/10.1111/bjop.12260
